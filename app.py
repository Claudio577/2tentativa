import streamlit as st
from config import get_llm

import os
import inspect

st.title("ğŸ” DEBUG â€” Qual app.py o Streamlit estÃ¡ executando?")

# 1 â€” Mostra caminho do arquivo real
st.subheader("ğŸ“Œ Caminho do arquivo em execuÃ§Ã£o:")
st.code(os.path.abspath(__file__))

# 2 â€” Mostra conteÃºdo do arquivo
st.subheader("ğŸ“Œ ConteÃºdo REAL do arquivo em execuÃ§Ã£o:")
with open(__file__, "r") as f:
    st.code(f.read())

# 3 â€” Lista todos os .py do projeto
st.subheader("ğŸ“Œ Arquivos Python detectados no projeto:")
for root, dirs, files in os.walk("/mount/src"):
    for file in files:
        if file.endswith(".py"):
            st.write(os.path.join(root, file))

st.info("Envie a screenshot desse resultado aqui.")

st.set_page_config(page_title="Agente Executivo", page_icon="ğŸ’¼")

st.title("ğŸ’¼ Agente Executivo â€” LangChain + Streamlit")

st.write("Envie uma pergunta para o agente executivo baseado em GPT-4o-mini:")

# cria agente simples
def criar_agente_executivo():
    llm = get_llm()

    def agente(user_input):
        messages = [
            {"role": "system", "content": "VocÃª Ã© um executivo sÃªnior especialista em estratÃ©gia corporativa."},
            {"role": "user", "content": user_input}
        ]
        return llm(messages)

    return agente


user_input = st.text_area("Sua mensagem:", height=120)

if st.button("Enviar"):
    if not user_input.strip():
        st.warning("Digite uma mensagem antes de enviar.")
    else:
        with st.spinner("Gerando resposta..."):
            try:
                agente = criar_agente_executivo()
                resposta = agente(user_input)

                st.subheader("ğŸ“˜ Resposta do Agente:")
                st.write(resposta)

            except Exception as e:
                st.error(f"Ocorreu um erro ao gerar a resposta: {e}")

st.markdown("---")
st.caption("AplicaÃ§Ã£o construÃ­da com Streamlit + OpenAI")
